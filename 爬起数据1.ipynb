{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab7a2e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/103] 正在爬取... 成功获取 50 条\n",
      "[2/103] 正在爬取... 成功获取 50 条\n",
      "[3/103] 正在爬取... 成功获取 50 条\n",
      "[4/103] 正在爬取... 成功获取 50 条\n",
      "[5/103] 正在爬取... 成功获取 50 条\n",
      "[6/103] 正在爬取... 成功获取 50 条\n",
      "[7/103] 正在爬取... 成功获取 50 条\n",
      "[8/103] 正在爬取... 成功获取 50 条\n",
      "[9/103] 正在爬取... 成功获取 50 条\n",
      "[10/103] 正在爬取... 成功获取 50 条\n",
      "[11/103] 正在爬取... 成功获取 50 条\n",
      "[12/103] 正在爬取... 成功获取 50 条\n",
      "[13/103] 正在爬取... 成功获取 50 条\n",
      "[14/103] 正在爬取... 成功获取 50 条\n",
      "[15/103] 正在爬取... 成功获取 50 条\n",
      "[16/103] 正在爬取... 成功获取 50 条\n",
      "[17/103] 正在爬取... 成功获取 50 条\n",
      "[18/103] 正在爬取... 成功获取 50 条\n",
      "[19/103] 正在爬取... 成功获取 50 条\n",
      "[20/103] 正在爬取... 成功获取 50 条\n",
      "[21/103] 正在爬取... 成功获取 50 条\n",
      "[22/103] 正在爬取... 成功获取 50 条\n",
      "[23/103] 正在爬取... 成功获取 50 条\n",
      "[24/103] 正在爬取... 成功获取 50 条\n",
      "[25/103] 正在爬取... 成功获取 50 条\n",
      "[26/103] 正在爬取... 成功获取 50 条\n",
      "[27/103] 正在爬取... 成功获取 50 条\n",
      "[28/103] 正在爬取... 成功获取 50 条\n",
      "[29/103] 正在爬取... 成功获取 50 条\n",
      "[30/103] 正在爬取... 成功获取 50 条\n",
      "[31/103] 正在爬取... 成功获取 50 条\n",
      "[32/103] 正在爬取... 成功获取 50 条\n",
      "[33/103] 正在爬取... 成功获取 50 条\n",
      "[34/103] 正在爬取... 成功获取 50 条\n",
      "[35/103] 正在爬取... 成功获取 50 条\n",
      "[36/103] 正在爬取... 成功获取 50 条\n",
      "[37/103] 正在爬取... 成功获取 50 条\n",
      "[38/103] 正在爬取... 成功获取 50 条\n",
      "[39/103] 正在爬取... 成功获取 50 条\n",
      "[40/103] 正在爬取... 成功获取 50 条\n",
      "[41/103] 正在爬取... 成功获取 50 条\n",
      "[42/103] 正在爬取... 成功获取 50 条\n",
      "[43/103] 正在爬取... 成功获取 50 条\n",
      "[44/103] 正在爬取... 成功获取 50 条\n",
      "[45/103] 正在爬取... 成功获取 50 条\n",
      "[46/103] 正在爬取... 成功获取 50 条\n",
      "[47/103] 正在爬取... 成功获取 50 条\n",
      "[48/103] 正在爬取... 成功获取 50 条\n",
      "[49/103] 正在爬取... 成功获取 50 条\n",
      "[50/103] 正在爬取... 成功获取 50 条\n",
      "[51/103] 正在爬取... 成功获取 50 条\n",
      "[52/103] 正在爬取... 成功获取 50 条\n",
      "[53/103] 正在爬取... 成功获取 50 条\n",
      "[54/103] 正在爬取... 成功获取 50 条\n",
      "[55/103] 正在爬取... 成功获取 50 条\n",
      "[56/103] 正在爬取... 成功获取 50 条\n",
      "[57/103] 正在爬取... 成功获取 50 条\n",
      "[58/103] 正在爬取... 成功获取 50 条\n",
      "[59/103] 正在爬取... 成功获取 50 条\n",
      "[60/103] 正在爬取... 成功获取 50 条\n",
      "[61/103] 正在爬取... 成功获取 50 条\n",
      "[62/103] 正在爬取... 成功获取 50 条\n",
      "[63/103] 正在爬取... 成功获取 50 条\n",
      "[64/103] 正在爬取... 成功获取 50 条\n",
      "[65/103] 正在爬取... 成功获取 50 条\n",
      "[66/103] 正在爬取... 成功获取 50 条\n",
      "[67/103] 正在爬取... 成功获取 50 条\n",
      "[68/103] 正在爬取... 成功获取 50 条\n",
      "[69/103] 正在爬取... 成功获取 50 条\n",
      "[70/103] 正在爬取... 成功获取 50 条\n",
      "[71/103] 正在爬取... 成功获取 50 条\n",
      "[72/103] 正在爬取... 成功获取 50 条\n",
      "[73/103] 正在爬取... 成功获取 50 条\n",
      "[74/103] 正在爬取... 成功获取 50 条\n",
      "[75/103] 正在爬取... 成功获取 50 条\n",
      "[76/103] 正在爬取... 成功获取 50 条\n",
      "[77/103] 正在爬取... 成功获取 50 条\n",
      "[78/103] 正在爬取... 成功获取 50 条\n",
      "[79/103] 正在爬取... 成功获取 50 条\n",
      "[80/103] 正在爬取... 成功获取 50 条\n",
      "[81/103] 正在爬取... 成功获取 50 条\n",
      "[82/103] 正在爬取... 成功获取 50 条\n",
      "[83/103] 正在爬取... 成功获取 50 条\n",
      "[84/103] 正在爬取... 成功获取 50 条\n",
      "[85/103] 正在爬取... 成功获取 50 条\n",
      "[86/103] 正在爬取... 成功获取 50 条\n",
      "[87/103] 正在爬取... 成功获取 50 条\n",
      "[88/103] 正在爬取... 成功获取 50 条\n",
      "[89/103] 正在爬取... 成功获取 50 条\n",
      "[90/103] 正在爬取... 成功获取 50 条\n",
      "[91/103] 正在爬取... 成功获取 50 条\n",
      "[92/103] 正在爬取... 成功获取 50 条\n",
      "[93/103] 正在爬取... 成功获取 50 条\n",
      "[94/103] 正在爬取... 成功获取 50 条\n",
      "[95/103] 正在爬取... 成功获取 50 条\n",
      "[96/103] 正在爬取... 成功获取 50 条\n",
      "[97/103] 正在爬取... 成功获取 50 条\n",
      "[98/103] 正在爬取... 成功获取 50 条\n",
      "[99/103] 正在爬取... 成功获取 50 条\n",
      "[100/103] 正在爬取... 成功获取 50 条\n",
      "[101/103] 正在爬取... 成功获取 50 条\n",
      "[102/103] 正在爬取... 成功获取 50 条\n",
      "[103/103] 正在爬取... 成功获取 1 条\n",
      "\n",
      ">>> 爬取结束，共获取 5101 条数据 <<<\n",
      "             辅导对象          辅导机构                 备案时间  辅导状态   派出机构    报告类型  \\\n",
      "0    安徽久易农业股份有限公司    国元证券股份有限公司  2025-12-01 00:00:00  辅导备案  安徽证监局  辅导备案报告   \n",
      "1    宁夏维尔精工股份有限公司    开源证券股份有限公司  2025-12-01 00:00:00  辅导备案  宁夏证监局  辅导备案报告   \n",
      "2    北京凝思软件股份有限公司  华泰联合证券有限责任公司  2025-11-27 00:00:00  辅导备案  北京证监局  辅导备案报告   \n",
      "3    武汉卓目科技股份有限公司  长江证券承销保荐有限公司  2025-11-26 00:00:00  辅导备案  湖北监管局  辅导备案报告   \n",
      "4  浙江贝尔轨道装备股份有限公司    广发证券股份有限公司  2025-11-26 00:00:00  辅导备案  浙江证监局  辅导备案报告   \n",
      "\n",
      "                                        报告标题  \n",
      "0            关于安徽久易农业股份有限公司首次公开发行股票并上市辅导备案报告  \n",
      "1            关于宁夏维尔精工股份有限公司首次公开发行股票并上市辅导备案报告  \n",
      "2            关于北京凝思软件股份有限公司首次公开发行股票并上市辅导备案报告  \n",
      "3            关于武汉卓目科技股份有限公司首次公开发行股票并上市辅导备案报告  \n",
      "4  关于与广发证券股份有限公司签订辅导协议暨申请公开发行股票并在北交所上市辅导备案公告  \n",
      "文件已保存为: ipo_fudao_data_fixed.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "def fetch_ipo_fudao_data(total_pages_to_scrape=103):\n",
    "    # 接口地址\n",
    "    url = \"https://datacenter-web.eastmoney.com/api/data/v1/get\"\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "        'Referer': 'https://data.eastmoney.com/xg/ipo/fd.html',\n",
    "        'Accept': 'application/json, text/javascript, */*; q=0.01'\n",
    "    }\n",
    "\n",
    "    # 配置自动重试机制 (防止网络波动导致的中断)\n",
    "    session = requests.Session()\n",
    "    retry_strategy = Retry(total=3, backoff_factor=1, status_forcelist=[500, 502, 503, 504])\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    session.mount(\"http://\", adapter)\n",
    "\n",
    "    all_data_list = []\n",
    "    \n",
    "    # ----------------------------------------------------\n",
    "    # 根据你的数据反馈，使用正确的参数配置\n",
    "    # ----------------------------------------------------\n",
    "    params_base = {\n",
    "        'sortColumns': 'RECORD_DATE,ORG_CODE', # 根据数据里的日期字段猜测排序\n",
    "        'sortTypes': '-1,-1',\n",
    "        'pageSize': '50',\n",
    "        # 注意：这里假设你用的 reportName 能返回你提供的那段 JSON\n",
    "        # 如果代码跑不通，请检查 reportName 是否为 'RPT_IPO_FUDAO' 或 'RPT_Public_TutorInfo'\n",
    "        'reportName': 'RPT_IPO_TUTRECORD', \n",
    "        'columns': 'ALL',\n",
    "        'source': 'WEB',\n",
    "        'client': 'WEB'\n",
    "    }\n",
    "\n",
    "    for page in range(1, total_pages_to_scrape + 1):\n",
    "        print(f\"[{page}/{total_pages_to_scrape}] 正在爬取...\", end=\"\")\n",
    "        \n",
    "        params = params_base.copy()\n",
    "        params['pageNumber'] = page\n",
    "\n",
    "        try:\n",
    "            # timeout 设置为 20 秒\n",
    "            response = session.get(url, headers=headers, params=params, timeout=20)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data_json = response.json()\n",
    "                \n",
    "                if data_json.get('result') and data_json['result'].get('data'):\n",
    "                    items = data_json['result']['data']\n",
    "                    print(f\" 成功获取 {len(items)} 条\")\n",
    "                    \n",
    "                    # -------------------------------------------------------\n",
    "                    # 【核心修改】基于你提供的 JSON 数据进行字段映射\n",
    "                    # -------------------------------------------------------\n",
    "                    for item in items:\n",
    "                        row = {\n",
    "                            '辅导对象': item.get('TUTOR_OBJECT'),      # 原数据: TUTOR_OBJECT\n",
    "                            '辅导机构': item.get('TUTOR_ORG'),         # 原数据: TUTOR_ORG\n",
    "                            '备案时间': item.get('RECORD_DATE'),       # 原数据: RECORD_DATE\n",
    "                            '辅导状态': item.get('TUTOR_PROCESS_STATE'), # 原数据: TUTOR_PROCESS_STATE\n",
    "                            '派出机构': item.get('DISPATCH_ORG'),      # 原数据: DISPATCH_ORG (可作为地区参考)\n",
    "                            '报告类型': item.get('REPORT_TYPE'),       # 原数据: REPORT_TYPE\n",
    "                            '报告标题': item.get('REPORT_TITLE')       # 原数据: REPORT_TITLE\n",
    "                        }\n",
    "                        all_data_list.append(row)\n",
    "                else:\n",
    "                    print(\"\\n数据已爬完（接口无返回）。\")\n",
    "                    break\n",
    "            else:\n",
    "                print(f\" 接口报错: {response.status_code}\")\n",
    "                \n",
    "            time.sleep(1) # 每一页暂停1秒，防止封IP\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n第 {page} 页失败: {e}\")\n",
    "            continue\n",
    "\n",
    "    # 保存数据\n",
    "    if all_data_list:\n",
    "        df = pd.DataFrame(all_data_list)\n",
    "        print(f\"\\n>>> 爬取结束，共获取 {len(df)} 条数据 <<<\")\n",
    "        print(df.head())\n",
    "        \n",
    "        filename = \"ipo_fudao_data_fixed.xlsx\"\n",
    "        df.to_excel(filename, index=False)\n",
    "        print(f\"文件已保存为: {filename}\")\n",
    "    else:\n",
    "        print(\"未抓取到任何数据。\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_ipo_fudao_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
