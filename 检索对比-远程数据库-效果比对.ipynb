{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b82bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨è¯»å–æ–‡ä»¶: d:\\jupyter\\api_retrieval_split_result.xlsx\n",
      "å…± 83 æ¡æ•°æ®ï¼Œä½¿ç”¨ 8 çº¿ç¨‹å¹¶å‘å¤„ç†...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AIåˆ†æä¸­: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [53:04<00:00, 38.36s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆ†æå®Œæˆï¼Œæ­£åœ¨å†™å…¥ Excel...\n",
      "ğŸ‰ å¤„ç†æˆåŠŸï¼ç»“æœä¿å­˜åœ¨: d:\\jupyter\\final_analysis_comparison.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import concurrent.futures\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm  # è¿›åº¦æ¡åº“ï¼Œå¦‚æœæ²¡å®‰è£…è¯· pip install tqdm\n",
    "\n",
    "# ================= é…ç½®åŒºåŸŸ =================\n",
    "\n",
    "# 1. å¤§æ¨¡å‹é…ç½®\n",
    "LLM_API_KEY = \"EMPTY\"\n",
    "LLM_API_BASE = \"http://192.168.6.117:19534/v1\"\n",
    "MODEL_NAME = \"Qwen/Qwen3-32B\"\n",
    "\n",
    "# 2. å¹¶å‘æ•°é‡ (æ ¹æ®ä½ æœåŠ¡å™¨çš„æ‰¿å—èƒ½åŠ›è°ƒæ•´ï¼Œå»ºè®® 5-10)\n",
    "MAX_WORKERS = 8 \n",
    "\n",
    "# 3. æ–‡ä»¶è·¯å¾„\n",
    "try:\n",
    "    CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    CURRENT_DIR = os.getcwd()\n",
    "\n",
    "# è¾“å…¥æ–‡ä»¶ (ä½ åˆšåˆšä¸Šä¼ çš„æ–‡ä»¶å)\n",
    "INPUT_FILENAME = \"api_retrieval_split_result.xlsx\"\n",
    "INPUT_PATH = os.path.join(CURRENT_DIR, INPUT_FILENAME)\n",
    "\n",
    "# è¾“å‡ºæ–‡ä»¶\n",
    "OUTPUT_PATH = os.path.join(CURRENT_DIR, \"final_analysis_comparison.xlsx\")\n",
    "\n",
    "# ===========================================\n",
    "\n",
    "# åˆå§‹åŒ–å®¢æˆ·ç«¯ (åœ¨ä¸»è¿›ç¨‹åˆå§‹åŒ–ï¼Œä½†åœ¨çº¿ç¨‹ä¸­è°ƒç”¨æ˜¯å®‰å…¨çš„)\n",
    "client = OpenAI(api_key=LLM_API_KEY, base_url=LLM_API_BASE)\n",
    "\n",
    "def clean_model_output(text):\n",
    "    \"\"\"æ¸…æ´—æ¨¡å‹è¾“å‡ºï¼Œå»é™¤æ€è€ƒæ ‡ç­¾\"\"\"\n",
    "    if not text: return \"\"\n",
    "    cleaned_text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "def merge_columns(row, prefix, count):\n",
    "    \"\"\"\n",
    "    åˆå¹¶å¤šä¸ªå¬å›ç»“æœåˆ—ä¸ºä¸€ä¸ªå­—ç¬¦ä¸²\n",
    "    ä¾‹å¦‚: å¬å›ç»“æœ1 + å¬å›ç»“æœ2 ...\n",
    "    \"\"\"\n",
    "    content_list = []\n",
    "    for i in range(1, count + 1):\n",
    "        # å…¼å®¹ä¸¤ç§åˆ—åæ ¼å¼: \"æ–¹æ¡ˆ1_å¬å›ç»“æœ1\" æˆ– \"å¬å›ç»“æœ1\"\n",
    "        col_name = f\"{prefix}{i}\"\n",
    "        \n",
    "        # å¦‚æœæ‰¾ä¸åˆ°å¸¦å‰ç¼€çš„ï¼Œå°è¯•æ‰¾ä¸å¸¦å‰ç¼€çš„ (é’ˆå¯¹åŸé—®é¢˜å¬å›ç»“æœ)\n",
    "        if col_name not in row and prefix == \"å¬å›ç»“æœ\":\n",
    "             col_name = f\"å¬å›ç»“æœ{i}\"\n",
    "\n",
    "        if col_name in row and pd.notna(row[col_name]):\n",
    "            val = str(row[col_name]).strip()\n",
    "            if val:\n",
    "                content_list.append(f\"[ç»“æœ{i}]: {val}\")\n",
    "    \n",
    "    return \"\\n\".join(content_list)[:2000] # æˆªå–å‰2000å­—é˜²æ­¢Tokenæº¢å‡º\n",
    "\n",
    "def call_llm(prompt):\n",
    "    \"\"\"é€šç”¨LLMè°ƒç”¨å‡½æ•°\"\"\"\n",
    "    try:\n",
    "        chat_response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.3,\n",
    "            max_tokens=512\n",
    "        )\n",
    "        return clean_model_output(chat_response.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        return f\"åˆ†æå¤±è´¥: {str(e)}\"\n",
    "\n",
    "def analyze_single_row(row):\n",
    "    \"\"\"\n",
    "    å¤„ç†å•è¡Œæ•°æ®çš„æ ¸å¿ƒé€»è¾‘ï¼šæ‰§è¡Œ4æ¬¡åˆ†æ\n",
    "    \"\"\"\n",
    "    # 1. è·å–åŸºç¡€æ•°æ®\n",
    "    question = row.get('é—®é¢˜', row.get('åŸé—®é¢˜', ''))\n",
    "    \n",
    "    # è·å–ä¸‰ç»„å¬å›å†…å®¹\n",
    "    # A. åŸæœ‰å¬å› (å¬å›ç»“æœ1-5)\n",
    "    baseline_content = merge_columns(row, \"å¬å›ç»“æœ\", 5)\n",
    "    # B. æ–¹æ¡ˆ1å¬å› (æ–¹æ¡ˆ1_å¬å›ç»“æœ1-3)\n",
    "    scheme1_content = merge_columns(row, \"æ–¹æ¡ˆ1_å¬å›ç»“æœ\", 3)\n",
    "    # C. æ–¹æ¡ˆ2å¬å› (æ–¹æ¡ˆ2_å¬å›ç»“æœ1-3)\n",
    "    scheme2_content = merge_columns(row, \"æ–¹æ¡ˆ2_å¬å›ç»“æœ\", 3)\n",
    "\n",
    "    # --- ä»»åŠ¡ 1: æ–¹æ¡ˆ1 æ•ˆæœè¯„ä¼° ---\n",
    "    prompt_eval_1 = f\"\"\"\n",
    "è¯·è¯„ä¼°ä»¥ä¸‹æ£€ç´¢ç»“æœå¯¹é—®é¢˜çš„å›ç­”ä»·å€¼ã€‚\n",
    "ã€é—®é¢˜ã€‘ï¼š{question}\n",
    "ã€æ£€ç´¢ç»“æœã€‘ï¼š\n",
    "{scheme1_content}\n",
    "\n",
    "è¯·ç®€è¦è¯„ä»·ï¼šè¿™äº›å†…å®¹æ˜¯å¦è§£å†³äº†é—®é¢˜ï¼Ÿæœ‰å“ªäº›å…³é”®ä¿¡æ¯ï¼Ÿ(100å­—ä»¥å†…)\n",
    "\"\"\"\n",
    "    \n",
    "    # --- ä»»åŠ¡ 2: æ–¹æ¡ˆ2 æ•ˆæœè¯„ä¼° ---\n",
    "    prompt_eval_2 = f\"\"\"\n",
    "è¯·è¯„ä¼°ä»¥ä¸‹æ£€ç´¢ç»“æœå¯¹é—®é¢˜çš„å›ç­”ä»·å€¼ã€‚\n",
    "ã€é—®é¢˜ã€‘ï¼š{question}\n",
    "ã€æ£€ç´¢ç»“æœã€‘ï¼š\n",
    "{scheme2_content}\n",
    "\n",
    "è¯·ç®€è¦è¯„ä»·ï¼šè¿™äº›å†…å®¹æ˜¯å¦è§£å†³äº†é—®é¢˜ï¼Ÿæœ‰å“ªäº›å…³é”®ä¿¡æ¯ï¼Ÿ(100å­—ä»¥å†…)\n",
    "\"\"\"\n",
    "\n",
    "    # --- ä»»åŠ¡ 3: æ–¹æ¡ˆ1 vs åŸå¬å› å¯¹æ¯” ---\n",
    "    prompt_comp_1 = f\"\"\"\n",
    "è¯·å¯¹æ¯”ä¸¤ç»„æ£€ç´¢ç»“æœçš„è´¨é‡ã€‚\n",
    "ã€é—®é¢˜ã€‘ï¼š{question}\n",
    "ã€åŸå¬å›ç»“æœã€‘ï¼š\n",
    "{baseline_content}\n",
    "ã€æ–¹æ¡ˆ1å¬å›ç»“æœ(å•å¥æ‰©å†™)ã€‘ï¼š\n",
    "{scheme1_content}\n",
    "\n",
    "è¯·åˆ†æï¼šæ–¹æ¡ˆ1ç›¸æ¯”åŸå¬å›ç»“æœï¼Œæ˜¯æå‡äº†è¿˜æ˜¯ä¸‹é™äº†ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ(100å­—ä»¥å†…ï¼Œä¾§é‡å‡†ç¡®æ€§å’Œç›¸å…³æ€§)\n",
    "\"\"\"\n",
    "\n",
    "    # --- ä»»åŠ¡ 4: æ–¹æ¡ˆ2 vs åŸå¬å› å¯¹æ¯” ---\n",
    "    prompt_comp_2 = f\"\"\"\n",
    "è¯·å¯¹æ¯”ä¸¤ç»„æ£€ç´¢ç»“æœçš„è´¨é‡ã€‚\n",
    "ã€é—®é¢˜ã€‘ï¼š{question}\n",
    "ã€åŸå¬å›ç»“æœã€‘ï¼š\n",
    "{baseline_content}\n",
    "ã€æ–¹æ¡ˆ2å¬å›ç»“æœ(æ½œåœ¨è¿½é—®)ã€‘ï¼š\n",
    "{scheme2_content}\n",
    "\n",
    "è¯·åˆ†æï¼šæ–¹æ¡ˆ2ç›¸æ¯”åŸå¬å›ç»“æœï¼Œæä¾›äº†å“ªäº›ä¸åŒçš„è§†è§’ï¼Ÿæ˜¯æ›´å…¨é¢è¿˜æ˜¯æ›´æ‚ä¹±ï¼Ÿ(100å­—ä»¥å†…)\n",
    "\"\"\"\n",
    "\n",
    "    # ä¸²è¡Œè°ƒç”¨4æ¬¡ (å•ä¸ªçº¿ç¨‹å†…)\n",
    "    # ä¹Ÿå¯ä»¥åœ¨è¿™é‡Œå†å¼€å¹¶å‘ï¼Œä½†æ§åˆ¶æ•´ä½“è¡Œå¹¶å‘æ›´ç®€å•\n",
    "    res_eval_1 = call_llm(prompt_eval_1)\n",
    "    res_eval_2 = call_llm(prompt_eval_2)\n",
    "    res_comp_1 = call_llm(prompt_comp_1)\n",
    "    res_comp_2 = call_llm(prompt_comp_2)\n",
    "\n",
    "    return res_eval_1, res_eval_2, res_comp_1, res_comp_2\n",
    "\n",
    "def main():\n",
    "    print(f\"æ­£åœ¨è¯»å–æ–‡ä»¶: {INPUT_PATH}\")\n",
    "    if not os.path.exists(INPUT_PATH):\n",
    "        print(\"âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_excel(INPUT_PATH)\n",
    "    total_rows = len(df)\n",
    "    print(f\"å…± {total_rows} æ¡æ•°æ®ï¼Œä½¿ç”¨ {MAX_WORKERS} çº¿ç¨‹å¹¶å‘å¤„ç†...\")\n",
    "\n",
    "    # å‡†å¤‡ç»“æœå®¹å™¨\n",
    "    results_map = {\n",
    "        \"æ–¹æ¡ˆ1_æ•ˆæœè¯„ä¼°\": [],\n",
    "        \"æ–¹æ¡ˆ2_æ•ˆæœè¯„ä¼°\": [],\n",
    "        \"æ–¹æ¡ˆ1_vs_åŸå¬å›_å¯¹æ¯”\": [],\n",
    "        \"æ–¹æ¡ˆ2_vs_åŸå¬å›_å¯¹æ¯”\": []\n",
    "    }\n",
    "\n",
    "    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        # å°† DataFrame è½¬ä¸ºå­—å…¸åˆ—è¡¨æ–¹ä¾¿å¤„ç†\n",
    "        rows = df.to_dict('records')\n",
    "        \n",
    "        # æäº¤ä»»åŠ¡\n",
    "        # tqdm ç”¨äºæ˜¾ç¤ºè¿›åº¦æ¡\n",
    "        futures = list(tqdm(executor.map(analyze_single_row, rows), total=total_rows, desc=\"AIåˆ†æä¸­\"))\n",
    "\n",
    "        # æ”¶é›†ç»“æœ\n",
    "        for res in futures:\n",
    "            results_map[\"æ–¹æ¡ˆ1_æ•ˆæœè¯„ä¼°\"].append(res[0])\n",
    "            results_map[\"æ–¹æ¡ˆ2_æ•ˆæœè¯„ä¼°\"].append(res[1])\n",
    "            results_map[\"æ–¹æ¡ˆ1_vs_åŸå¬å›_å¯¹æ¯”\"].append(res[2])\n",
    "            results_map[\"æ–¹æ¡ˆ2_vs_åŸå¬å›_å¯¹æ¯”\"].append(res[3])\n",
    "\n",
    "    # å°†ç»“æœå†™å…¥ DataFrame\n",
    "    print(\"åˆ†æå®Œæˆï¼Œæ­£åœ¨å†™å…¥ Excel...\")\n",
    "    for col, data in results_map.items():\n",
    "        df[col] = data\n",
    "\n",
    "    try:\n",
    "        df.to_excel(OUTPUT_PATH, index=False)\n",
    "        print(f\"ğŸ‰ å¤„ç†æˆåŠŸï¼ç»“æœä¿å­˜åœ¨: {OUTPUT_PATH}\")\n",
    "    except PermissionError:\n",
    "        print(\"âŒ ä¿å­˜å¤±è´¥ï¼šè¯·å…³é—­ Excel æ–‡ä»¶åé‡è¯•ã€‚\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
