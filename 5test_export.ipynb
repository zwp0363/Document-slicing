{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739fd36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载文档...\n",
      "   -> 正在移除页眉 (header) 和页脚 (footer)...\n",
      "   -> 找到正文起始标记 '〖特别报告〗' (位于段落 0)。\n",
      "   -> 已成功清理正文标题行。\n",
      "   -> 已处理 23 个正文段落。\n",
      "   -> 中间 HTML 文件已清理。\n",
      "正在按段落切割 (合并目标: 500, 最小: 100, 硬上限: 1000)...\n",
      "初步切割得到 5 个块，正在进行小块合并...\n",
      "   -> 提示：第一个块 (Chunk 0) 长度 90 < 100。\n",
      "   -> (Chunk 0) 长度 90 太小，但无法与下一块合并 (会超长)。\n",
      "清理完成，最终得到 5 个文本块。\n",
      "\n",
      "==============================\n",
      "      最终切分效果预览      \n",
      "==============================\n",
      "\n",
      ">>> Chunk 0 (长度: 90)\n",
      "内容: 〖特别报告〗数字货币、加密货币、区块链甚嚣尘上 ——投机资本真的没方向 摘要：数字货币、加密货币、区块链等概念诞生于码农圈，成长于币圈，深入影响了互联网圈，又在...\n",
      "\n",
      ">>> Chunk 1 (长度: 553)\n",
      "内容: 币圈火了、疯了、乱了。2017年内比特币、莱特币、以太币分别暴涨14倍、76倍、80倍，名不见经传的瑞波币连涨360倍，一时风头无两；但到了2018年，行情斗转...\n",
      "\n",
      ">>> Chunk 2 (长度: 786)\n",
      "内容: 一时间，加密货币、Token、区块链概念惹得满城风雨，屡被混为一谈，其中关系剪不断、理还乱，为贪婪的庄家和投机的资本玩家提供了疯狂敛收智商税的好机会。与此同时，...\n",
      "\n",
      ">>> Chunk 3 (长度: 911)\n",
      "内容: （3）数字货币一般是指以数字形式存在的法定货币，由国家做信用背书，有价值锚定，具备信用创造功能，对经济产生实质作用。在加密货币颠覆货币体系的言论甚嚣尘上之时，为...\n",
      "\n",
      ">>> Chunk 4 (长度: 718)\n",
      "内容: 尽管加密货币的用户群体只有2000万，交易量只有外汇交易量的十万分之一，在峰值时的总市值尚且不到全球GDP的1%，但正如IMF总裁拉加德所描绘，“我们将见证异常...\n",
      "\n",
      "正在将 5 个块转换为 DataFrame...\n",
      "\n",
      "✅ 任务完成！已成功导出 5 条数据到：\n",
      "F:\\福卡\\福卡知识库测试文件\\4资本金融\\4-5科技金融\\20180425数字货币、加密货币、区块链甚嚣尘上————投机资本真的没方向.xlsx\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. 配置 ---\n",
    "SOURCE_DOC_FILE = \"F:\\\\福卡\\\\福卡知识库测试文件\\\\4资本金融\\\\4-5科技金融\\\\20180425数字货币、加密货币、区块链甚嚣尘上————投机资本真的没方向.doc\" \n",
    "# 自动将输出Excel放在源文档同一目录\n",
    "OUTPUT_EXCEL_FILE = os.path.join(os.path.dirname(os.path.abspath(SOURCE_DOC_FILE)), \n",
    "                                os.path.basename(SOURCE_DOC_FILE).rsplit('.', 1)[0] + '.xlsx')\n",
    "# 切割配置\n",
    "MAX_CHUNK_LEN = 500  # 合并的目标上限\n",
    "MIN_CHUNK_LEN = 100  # 合并的最小阈值\n",
    "HARD_MAX_LEN = 1000 # 单个段落的硬性拆分上限\n",
    "\n",
    "\n",
    "# --- 2. 文档加载 ---\n",
    "def find_libreoffice():\n",
    "    possible_paths = [\n",
    "        r\"C:\\\\Program Files\\\\LibreOffice\\\\program\\\\soffice.exe\",\n",
    "        r\"C:\\\\Program Files (x86)\\\\LibreOffice\\\\program\\\\soffice.exe\",\n",
    "        r\"D:\\\\LibreOffice\\\\program\\\\soffice.exe\",\n",
    "        \"soffice\"\n",
    "    ]\n",
    "    for path in possible_paths:\n",
    "        try:\n",
    "            if path != \"soffice\" and not os.path.exists(path): continue\n",
    "            result = subprocess.run([path, '--version'], capture_output=True, text=True, timeout=10)\n",
    "            if result.returncode == 0: return path\n",
    "        except: continue\n",
    "    return None\n",
    "\n",
    "def load_doc_as_text(doc_path):\n",
    "    print(\"正在加载文档...\")\n",
    "    libreoffice_path = find_libreoffice()\n",
    "    if not libreoffice_path:\n",
    "        print(\"错误：未找到 LibreOffice (soffice.exe)，请检查路径。\")\n",
    "        return None\n",
    "    \n",
    "    doc_path = os.path.abspath(doc_path)\n",
    "    output_dir = os.path.dirname(doc_path)\n",
    "    html_filename = os.path.basename(doc_path).rsplit('.', 1)[0] + '.html'\n",
    "    html_path = os.path.join(output_dir, html_filename)\n",
    "    \n",
    "    if os.path.exists(html_path): \n",
    "        try: os.remove(html_path)\n",
    "        except: pass\n",
    "        \n",
    "    cmd = [libreoffice_path, '--headless', '--convert-to', 'html', '--outdir', output_dir, doc_path]\n",
    "    subprocess.run(cmd, capture_output=True, text=True)\n",
    "    \n",
    "    if not os.path.exists(html_path):\n",
    "        print(f\"错误：LibreOffice 转换失败，未在 {output_dir} 找到 {html_filename}\")\n",
    "        return None\n",
    "    \n",
    "    content = \"\"\n",
    "    for enc in ['utf-8', 'gb18030', 'gbk']:\n",
    "        try:\n",
    "            with open(html_path, 'r', encoding=enc) as f:\n",
    "                content = f.read()\n",
    "                break\n",
    "        except: continue\n",
    "            \n",
    "    if not content:\n",
    "        print(\"错误：读取转换后的 HTML 文件失败。\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    # 1. 移除页眉和页脚的 div\n",
    "    print(\"   -> 正在移除页眉 (header) 和页脚 (footer)...\")\n",
    "    header = soup.find('div', title='header')\n",
    "    if header:\n",
    "        header.decompose() \n",
    "\n",
    "    footer = soup.find('div', title='footer')\n",
    "    if footer:\n",
    "        footer.decompose()\n",
    "    \n",
    "    # 2. 获取所有非空段落\n",
    "    # 获取所有可能的文本标签，不仅仅是 p\n",
    "    # 包含段落(p), 各种标题(h1-h6), 分块(div), 列表项(li)\n",
    "    target_tags = ['p', 'div', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'li', 'blockquote']\n",
    "    found_tags = soup.find_all(target_tags)\n",
    "    \n",
    "    cleaned_paragraphs = []\n",
    "    for tag in found_tags:\n",
    "        # 1. 获取文本\n",
    "        p_text = tag.get_text()\n",
    "        \n",
    "        # 2. 移除标签内部的换行符\n",
    "        # LibreOffice 会在 HTML 标签内部插入 \\n 进行视觉换行，\n",
    "        # 这对于中文文档会导致句子被错误切断。必须将其替换为空字符串。\n",
    "        p_text = p_text.replace('\\n', '').replace('\\r', '')\n",
    "        \n",
    "        # 3. 去除首尾空白\n",
    "        p_text = p_text.strip()\n",
    "        \n",
    "        if p_text:\n",
    "            cleaned_paragraphs.append(p_text)\n",
    "\n",
    "    # 3. 找到正文开始的标记 \"〖特别报告〗\"，删除之前的内容\n",
    "    start_index = -1\n",
    "    for i, p_text in enumerate(cleaned_paragraphs):\n",
    "        if \"〖特别报告〗\" in p_text:\n",
    "            start_index = i\n",
    "            break\n",
    "    \n",
    "    final_paragraphs = []\n",
    "    if start_index != -1:\n",
    "        # 找到了标记\n",
    "        print(f\"   -> 找到正文起始标记 '〖特别报告〗' (位于段落 {start_index})。\")\n",
    "        \n",
    "        # 3a. 获取 *第一个* 正文段落\n",
    "        first_para_text = cleaned_paragraphs[start_index]\n",
    "        \n",
    "        # 3b. 【新】使用 .split() 来切分，这比 .find() 更健壮\n",
    "        # 这将创建列表: [\"福卡分析...福卡理念：...\", \" 世界改造中国...\"]\n",
    "        parts = first_para_text.split(\"〖特别报告〗\", 1)\n",
    "        \n",
    "        if len(parts) == 2:\n",
    "            # 成功切分. parts[0] 是垃圾页眉, parts[1] 是正文.\n",
    "            # 我们重新组合，保留标记和正文。\n",
    "            cleaned_first_para = \"〖特别报告〗\" + parts[1]\n",
    "            final_paragraphs.append(cleaned_first_para.strip()) # 添加清理后的第一段\n",
    "            print(f\"   -> 已成功清理正文标题行。\")\n",
    "        else:\n",
    "            # 切分失败（极不可能，但作为保险）\n",
    "            print(\"   -> 警告: 'split' 失败，按原样保留段落。\")\n",
    "            final_paragraphs.append(first_para_text)\n",
    "            \n",
    "        # 3c. 添加所有剩余的段落\n",
    "        final_paragraphs.extend(cleaned_paragraphs[start_index + 1:])\n",
    "        print(f\"   -> 已处理 {len(final_paragraphs)} 个正文段落。\")\n",
    "\n",
    "    else:\n",
    "        # 没找到标记\n",
    "        print(\"   -> 警告：未找到 '〖特别报告〗' 标记，将处理所有段落。\")\n",
    "        final_paragraphs = cleaned_paragraphs\n",
    "    \n",
    "    # 4. 用单一的、可靠的 \\n 将所有“干净”的段落连接起来\n",
    "    text = \"\\n\".join(final_paragraphs)\n",
    "    \n",
    "    try: \n",
    "        os.remove(html_path) \n",
    "        print(\"   -> 中间 HTML 文件已清理。\")\n",
    "    except: \n",
    "        pass\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "# --- 3. 语义切割逻辑 ---\n",
    "def split_long_paragraph(text, hard_max):\n",
    "    print(f\"   -> 检测到长段落 (长度 {len(text)})，尝试按中间句号 '。' 切分...\")\n",
    "    mid_point = len(text) // 2\n",
    "    \n",
    "    pos_before = text.rfind('。', 0, mid_point)\n",
    "    pos_after = text.find('。', mid_point)\n",
    "    \n",
    "    split_pos = -1\n",
    "    \n",
    "    if pos_before != -1 and pos_after != -1:\n",
    "        if (mid_point - pos_before) < (pos_after - mid_point):\n",
    "            split_pos = pos_before\n",
    "        else:\n",
    "            split_pos = pos_after\n",
    "    elif pos_before != -1:\n",
    "        split_pos = pos_before\n",
    "    elif pos_after != -1:\n",
    "        split_pos = pos_after\n",
    "    else:\n",
    "        print(f\"   -> 警告: 段落长度 {len(text)} > {hard_max}，但未找到 '。' 无法切分。\")\n",
    "        return [text] \n",
    "    \n",
    "    part1 = text[:split_pos + 1].strip()\n",
    "    part2 = text[split_pos + 1:].strip()\n",
    "    \n",
    "    if not part1 or not part2:\n",
    "         print(f\"   -> 警告: 按句号切分失败 (产生空块)，返回原长段落。\")\n",
    "         return [text]\n",
    "         \n",
    "    print(f\"   -> S 成功切分为两块: (长度 {len(part1)}) 和 (长度 {len(part2)})\")\n",
    "    return [part1, part2]\n",
    "\n",
    "\n",
    "def split_text_smart(text, max_len=MAX_CHUNK_LEN, min_len=MIN_CHUNK_LEN):\n",
    "    print(f\"正在按段落切割 (合并目标: {max_len}, 最小: {min_len}, 硬上限: {HARD_MAX_LEN})...\")\n",
    "    \n",
    "    # 1. 移除\"相关链接\"\n",
    "    text = re.split(r\"〖相关链接：信息〗|〖相关链接：报告〗|〖参考信息〗|〖参考报告〗\", text, 1)[0]\n",
    "    \n",
    "    # 2. 基础清理\n",
    "    text = re.sub(r\"\\\"\", \"\", text)\n",
    "    text = re.sub(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1f\\x7f-\\x9f]\", \"\", text) # 保留 \\n \\r \\t\n",
    "    text = re.sub(r\"[\\r\\n\\t ]+\\n\", \"\\n\", text)\n",
    "    text = re.sub(r\"\\n\\s*\\n\", \"\\n\", text).strip()\n",
    "    \n",
    "    paragraphs = text.split('\\n')\n",
    "    paragraphs = [p.strip() for p in paragraphs if p.strip()]\n",
    "\n",
    "    # 3. 长度控制\n",
    "    initial_chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for para in paragraphs:\n",
    "        # 3a. 检查 > 1000\n",
    "        if len(para) > HARD_MAX_LEN:\n",
    "            sub_paragraphs = split_long_paragraph(para, HARD_MAX_LEN)\n",
    "        else:\n",
    "            sub_paragraphs = [para]\n",
    "\n",
    "        # 3b. 迭代处理(可能被切分后)的段落，并应用 < 500 合并逻辑\n",
    "        for sub_para in sub_paragraphs:\n",
    "            if not sub_para.strip(): continue \n",
    "            \n",
    "            if not current_chunk:\n",
    "                current_chunk = sub_para\n",
    "            elif len(current_chunk) + len(sub_para) + 1 <= max_len: \n",
    "                current_chunk += \"\\n\" + sub_para\n",
    "            else:\n",
    "                initial_chunks.append(current_chunk)\n",
    "                current_chunk = sub_para\n",
    "    \n",
    "    if current_chunk:\n",
    "        initial_chunks.append(current_chunk)\n",
    "        \n",
    "    print(f\"初步切割得到 {len(initial_chunks)} 个块，正在进行小块合并...\")\n",
    "\n",
    "    # 4. 后处理：合并 < 100 的块\n",
    "    final_chunks = []\n",
    "    i = 0\n",
    "    while i < len(initial_chunks):\n",
    "        current_chunk = initial_chunks[i]\n",
    "        \n",
    "        if i == 0 and len(current_chunk) < min_len:\n",
    "             print(f\"   -> 提示：第一个块 (Chunk 0) 长度 {len(current_chunk)} < {min_len}。\")\n",
    "        \n",
    "        if len(current_chunk) < min_len and (i < len(initial_chunks) - 1):\n",
    "            next_chunk = initial_chunks[i+1]\n",
    "            merged_chunk = current_chunk + \"\\n\" + next_chunk\n",
    "            \n",
    "            if len(merged_chunk) <= max_len:\n",
    "                print(f\"   -> (Chunk {i}) 长度 {len(current_chunk)} 太小，已与下一块合并。\")\n",
    "                final_chunks.append(merged_chunk)\n",
    "                i += 2 \n",
    "            else:\n",
    "                print(f\"   -> (Chunk {i}) 长度 {len(current_chunk)} 太小，但无法与下一块合并 (会超长)。\")\n",
    "                final_chunks.append(current_chunk)\n",
    "                i += 1\n",
    "        else:\n",
    "            final_chunks.append(current_chunk)\n",
    "            i += 1\n",
    "\n",
    "    print(f\"清理完成，最终得到 {len(final_chunks)} 个文本块。\")\n",
    "    return final_chunks\n",
    "\n",
    "\n",
    "# --- 4. 主程序 ---\n",
    "def main():\n",
    "    # 确保文件存在\n",
    "    if not os.path.exists(SOURCE_DOC_FILE):\n",
    "        print(f\"❌ 错误：源文件未找到！\")\n",
    "        print(f\"请检查 'SOURCE_DOC_FILE' 变量是否指向正确的文件：\")\n",
    "        print(f\"{os.path.abspath(SOURCE_DOC_FILE)}\")\n",
    "        return\n",
    "        \n",
    "    full_text = load_doc_as_text(SOURCE_DOC_FILE)\n",
    "    if not full_text: \n",
    "        print(\"❌ 错误：未能加载文档。\")\n",
    "        return\n",
    "\n",
    "    # 1. 执行切割\n",
    "    chunks = split_text_smart(full_text)\n",
    "    \n",
    "    if not chunks:\n",
    "        print(\"❌ 错误：切割后未产生任何文本块。\")\n",
    "        return\n",
    "\n",
    "    # 2. 预览检查\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"      最终切分效果预览      \")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if i < 5: \n",
    "            print(f\"\\n>>> Chunk {i} (长度: {len(chunk)})\")\n",
    "            preview = chunk.replace(\"\\n\", \" \")[:80]\n",
    "            print(f\"内容: {preview}...\")\n",
    "            \n",
    "    if len(chunks) > 5:\n",
    "        print(f\"\\n... (及其他 {len(chunks) - 5} 个块)\")\n",
    "    \n",
    "    \n",
    "    # 3. 转换为 DataFrame\n",
    "    print(f\"\\n正在将 {len(chunks)} 个块转换为 DataFrame...\")\n",
    "    \n",
    "    df = pd.DataFrame(chunks, columns=['text_content'])\n",
    "    df['length'] = df['text_content'].str.len()\n",
    "    df['chunk_id'] = range(1, len(df) + 1)\n",
    "    \n",
    "    # 调整列顺序\n",
    "    df = df[['chunk_id', 'text_content', 'length']]\n",
    "    \n",
    "    # 4. 导出到 Excel\n",
    "    try:\n",
    "        df.to_excel(OUTPUT_EXCEL_FILE, index=False, engine='openpyxl')\n",
    "        print(f\"\\n✅ 任务完成！已成功导出 {len(df)} 条数据到：\")\n",
    "        print(f\"{os.path.abspath(OUTPUT_EXCEL_FILE)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 导出 Excel 失败：{e}\")\n",
    "        print(\"提示：如果文件已打开，请关闭它再重试。\")\n",
    "    \n",
    "# --- 运行 ---\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
