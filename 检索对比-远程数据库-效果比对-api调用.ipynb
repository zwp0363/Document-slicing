{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695ec0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨è¯»å–æ–‡ä»¶: d:\\jupyter\\api_retrieval_split_result.xlsx\n",
      "å…± 83 æ¡æ•°æ®ï¼Œä½¿ç”¨ 5 çº¿ç¨‹å¹¶å‘å¤„ç†...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "é˜¿é‡Œäº‘LLMåˆ†æä¸­: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:51<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆ†æå®Œæˆï¼Œæ­£åœ¨ä¿å­˜...\n",
      "ğŸ‰ å¤„ç†æˆåŠŸï¼ç»“æœä¿å­˜åœ¨: d:\\jupyter\\final_analysis_comparison_aliyun.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import concurrent.futures\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# ================= é…ç½®åŒºåŸŸ =================\n",
    "\n",
    "# 1. å¤§æ¨¡å‹é…ç½® (é˜¿é‡Œäº‘ DashScope)\n",
    "LLM_API_KEY = \"sk-fa13f585000140deabdfa506b25a7f3d\"\n",
    "# é˜¿é‡Œäº‘ OpenAI å…¼å®¹æ¥å£åœ°å€\n",
    "LLM_API_BASE = \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "MODEL_NAME = \"qwen3-30b-a3b-instruct-2507\" # æˆ–è€…æ˜¯ qwen-plus / qwen-maxï¼Œè¯·ç¡®ä¿æ‚¨æœ‰è¯¥æ¨¡å‹æƒé™\n",
    "\n",
    "# 2. å¹¶å‘æ•°é‡\n",
    "# äº‘ç«¯æ¥å£é€šå¸¸æœ‰é€Ÿç‡é™åˆ¶(RPM/TPM)ï¼Œå»ºè®®ä¸è¦è®¾ç½®è¿‡å¤§ï¼Œ5-8 æ¯”è¾ƒç¨³å¦¥\n",
    "MAX_WORKERS = 5\n",
    "\n",
    "# 3. æ–‡ä»¶è·¯å¾„\n",
    "try:\n",
    "    CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    CURRENT_DIR = os.getcwd()\n",
    "\n",
    "# è¾“å…¥æ–‡ä»¶\n",
    "INPUT_FILENAME = \"api_retrieval_split_result.xlsx\"\n",
    "INPUT_PATH = os.path.join(CURRENT_DIR, INPUT_FILENAME)\n",
    "\n",
    "# è¾“å‡ºæ–‡ä»¶\n",
    "OUTPUT_PATH = os.path.join(CURRENT_DIR, \"final_analysis_comparison_aliyun.xlsx\")\n",
    "\n",
    "# ===========================================\n",
    "\n",
    "# åˆå§‹åŒ–å®¢æˆ·ç«¯\n",
    "client = OpenAI(api_key=LLM_API_KEY, base_url=LLM_API_BASE)\n",
    "\n",
    "def clean_model_output(text):\n",
    "    \"\"\"æ¸…æ´—æ¨¡å‹è¾“å‡º\"\"\"\n",
    "    if not text: return \"\"\n",
    "    text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)\n",
    "    text = text.replace('```', '').strip()\n",
    "    return text\n",
    "\n",
    "def merge_columns(row, prefix, count):\n",
    "    \"\"\"åˆå¹¶å¤šä¸ªå¬å›ç»“æœåˆ—\"\"\"\n",
    "    content_list = []\n",
    "    for i in range(1, count + 1):\n",
    "        col_name = f\"{prefix}{i}\"\n",
    "        if col_name not in row and prefix == \"å¬å›ç»“æœ\":\n",
    "             col_name = f\"å¬å›ç»“æœ{i}\"\n",
    "\n",
    "        if col_name in row and pd.notna(row[col_name]):\n",
    "            val = str(row[col_name]).strip()\n",
    "            if val and val not in content_list:\n",
    "                content_list.append(f\"[{i}]: {val}\")\n",
    "    \n",
    "    return \"\\n\".join(content_list)[:2500]\n",
    "\n",
    "def call_llm_with_retry(prompt, retries=3):\n",
    "    \"\"\"å¸¦é‡è¯•æœºåˆ¶çš„LLMè°ƒç”¨\"\"\"\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            chat_response = client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªç²¾å‡†çš„æ•°æ®åˆ†æå¸ˆã€‚è¯·ç›´æ¥è¾“å‡ºåˆ†æç»“æœï¼Œä¸¥ç¦åŒ…å«æ€è€ƒè¿‡ç¨‹(<think>)ï¼Œä¸¥ç¦è¾“å‡ºå®¢å¥—è¯ã€‚å­—æ•°ä¸¥æ ¼æ§åˆ¶åœ¨100å­—ä»¥å†…ã€‚\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.1,\n",
    "                max_tokens=256\n",
    "            )\n",
    "            return clean_model_output(chat_response.choices[0].message.content)\n",
    "        except Exception as e:\n",
    "            if i == retries - 1:\n",
    "                return f\"è°ƒç”¨å¤±è´¥: {str(e)}\"\n",
    "            time.sleep(1) # å¤±è´¥ç­‰å¾…1ç§’é‡è¯•\n",
    "    return \"è°ƒç”¨å¤±è´¥\"\n",
    "\n",
    "def analyze_single_row(row):\n",
    "    \"\"\"å¤„ç†å•è¡Œæ•°æ®\"\"\"\n",
    "    try:\n",
    "        question = str(row.get('é—®é¢˜', row.get('åŸé—®é¢˜', '')))\n",
    "        \n",
    "        baseline_content = merge_columns(row, \"å¬å›ç»“æœ\", 5)\n",
    "        scheme1_content = merge_columns(row, \"æ–¹æ¡ˆ1_å¬å›ç»“æœ\", 3)\n",
    "        scheme2_content = merge_columns(row, \"æ–¹æ¡ˆ2_å¬å›ç»“æœ\", 3)\n",
    "\n",
    "        if not baseline_content: baseline_content = \"ï¼ˆæ— å¬å›å†…å®¹ï¼‰\"\n",
    "        if not scheme1_content: scheme1_content = \"ï¼ˆæ— å¬å›å†…å®¹ï¼‰\"\n",
    "        if not scheme2_content: scheme2_content = \"ï¼ˆæ— å¬å›å†…å®¹ï¼‰\"\n",
    "\n",
    "        # Prompt 1: æ–¹æ¡ˆ1 è¯„ä¼°\n",
    "        p1 = f\"ã€é—®é¢˜ã€‘ï¼š{question}\\nã€æ£€ç´¢å†…å®¹ã€‘ï¼š{scheme1_content}\\nè¯·ä¸€å¥è¯è¯„ä¼°ï¼šä¸Šè¿°æ£€ç´¢å†…å®¹æ˜¯å¦åŒ…å«å›ç­”é—®é¢˜æ‰€éœ€çš„å…³é”®äº‹å®ï¼Ÿç¼ºå¤±äº†ä»€ä¹ˆï¼Ÿ(é™100å­—)\"\n",
    "        \n",
    "        # Prompt 2: æ–¹æ¡ˆ2 è¯„ä¼°\n",
    "        p2 = f\"ã€é—®é¢˜ã€‘ï¼š{question}\\nã€æ£€ç´¢å†…å®¹ã€‘ï¼š{scheme2_content}\\nè¯·ä¸€å¥è¯è¯„ä¼°ï¼šä¸Šè¿°æ£€ç´¢å†…å®¹æ˜¯å¦åŒ…å«å›ç­”é—®é¢˜æ‰€éœ€çš„å…³é”®äº‹å®ï¼Ÿç¼ºå¤±äº†ä»€ä¹ˆï¼Ÿ(é™100å­—)\"\n",
    "\n",
    "        # Prompt 3: æ–¹æ¡ˆ1 vs åŸå¬å›\n",
    "        p3 = f\"ã€é—®é¢˜ã€‘ï¼š{question}\\nã€åŸæ£€ç´¢ã€‘ï¼š{baseline_content}\\nã€æ–°æ£€ç´¢(é•¿éš¾å¥æ‰©å†™)ã€‘ï¼š{scheme1_content}\\nè¯·å¯¹æ¯”ï¼šæ–°æ£€ç´¢ç›¸æ¯”åŸæ£€ç´¢ï¼Œå‡†ç¡®æ€§æ˜¯æå‡è¿˜æ˜¯ä¸‹é™ï¼Ÿä¸»è¦ä½“ç°åœ¨å“ªï¼Ÿ(é™100å­—ï¼Œç›´æ¥ç»™ç»“è®º)\"\n",
    "\n",
    "        # Prompt 4: æ–¹æ¡ˆ2 vs åŸå¬å›\n",
    "        p4 = f\"ã€é—®é¢˜ã€‘ï¼š{question}\\nã€åŸæ£€ç´¢ã€‘ï¼š{baseline_content}\\nã€æ–°æ£€ç´¢(æ½œåœ¨è¿½é—®)ã€‘ï¼š{scheme2_content}\\nè¯·å¯¹æ¯”ï¼šæ–°æ£€ç´¢ç›¸æ¯”åŸæ£€ç´¢ï¼Œä¿¡æ¯ä¸°å¯Œåº¦æ˜¯æå‡è¿˜æ˜¯ä¸‹é™ï¼Ÿæ˜¯å¦å¼•å…¥äº†å™ªéŸ³ï¼Ÿ(é™100å­—ï¼Œç›´æ¥ç»™ç»“è®º)\"\n",
    "\n",
    "        # ä¸²è¡Œè°ƒç”¨4æ¬¡\n",
    "        r1 = call_llm_with_retry(p1)\n",
    "        r2 = call_llm_with_retry(p2)\n",
    "        r3 = call_llm_with_retry(p3)\n",
    "        r4 = call_llm_with_retry(p4)\n",
    "\n",
    "        return r1, r2, r3, r4\n",
    "\n",
    "    except Exception as e:\n",
    "        err_msg = f\"å¤„ç†å‡ºé”™: {str(e)}\"\n",
    "        return err_msg, err_msg, err_msg, err_msg\n",
    "\n",
    "def main():\n",
    "    print(f\"æ­£åœ¨è¯»å–æ–‡ä»¶: {INPUT_PATH}\")\n",
    "    if not os.path.exists(INPUT_PATH):\n",
    "        print(\"âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_excel(INPUT_PATH)\n",
    "    total_rows = len(df)\n",
    "    print(f\"å…± {total_rows} æ¡æ•°æ®ï¼Œä½¿ç”¨ {MAX_WORKERS} çº¿ç¨‹å¹¶å‘å¤„ç†...\")\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        rows = df.to_dict('records')\n",
    "        results_iterator = list(tqdm(executor.map(analyze_single_row, rows), total=total_rows, desc=\"é˜¿é‡Œäº‘LLMåˆ†æä¸­\"))\n",
    "        results_list = results_iterator\n",
    "\n",
    "    col1, col2, col3, col4 = [], [], [], []\n",
    "    for res in results_list:\n",
    "        col1.append(res[0])\n",
    "        col2.append(res[1])\n",
    "        col3.append(res[2])\n",
    "        col4.append(res[3])\n",
    "\n",
    "    df[\"æ–¹æ¡ˆ1_æ•ˆæœè¯„ä¼°\"] = col1\n",
    "    df[\"æ–¹æ¡ˆ2_æ•ˆæœè¯„ä¼°\"] = col2\n",
    "    df[\"æ–¹æ¡ˆ1_vs_åŸå¬å›_å¯¹æ¯”\"] = col3\n",
    "    df[\"æ–¹æ¡ˆ2_vs_åŸå¬å›_å¯¹æ¯”\"] = col4\n",
    "\n",
    "    print(\"åˆ†æå®Œæˆï¼Œæ­£åœ¨ä¿å­˜...\")\n",
    "    try:\n",
    "        df.to_excel(OUTPUT_PATH, index=False)\n",
    "        print(f\"ğŸ‰ å¤„ç†æˆåŠŸï¼ç»“æœä¿å­˜åœ¨: {OUTPUT_PATH}\")\n",
    "    except PermissionError:\n",
    "        print(\"âŒ ä¿å­˜å¤±è´¥ï¼šè¯·å…³é—­ Excel æ–‡ä»¶åé‡è¯•ã€‚\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
